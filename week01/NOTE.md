学习笔记：

任务：

task_one为作业一

task_two为作业二

运行结果：
task_one直接运行week01/maoYan.py

task_two直接运行week01/task_two/main.py,当然也可以直接在命令窗口运行''scrapy crawl MaoYanSpider'

本周课程总结：

对requests有了基本了解

了解了scrapy抓取框架原理，基本用法

发现requests比selenium效率更高

scrapy框架成熟，把多线程整合，抓取快，且比selenium自定义的多线程稳定